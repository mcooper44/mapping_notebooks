{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a collection of methods to aggregate some key household level data at the neighbourhood level.  \n",
    "It relies on the geopoints being included in the export (thanks fam) and makes use of the Neighbourhoods class to label the households and then uses the household labels to aggregate statistics about useage to the neighbourhood level.\n",
    "\n",
    "It is still a work in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kw_neighbourhoods import Neighbourhoods # borrowed from December_Ops collection\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdb = r'source_files/City of Waterloo and Kitchener Planning district Geometry.json'\n",
    "# opens a tinydb of geometries and provides a method to see if arbitrary geopoints are within one of the neighbourhoods \n",
    "# accessible by the object\n",
    "kw = Neighbourhoods(tdb)\n",
    "kw.extract_shapes() # takes geometries and organizes them in the .nhood_shapes attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_types = {'Latitude' : 'float',\n",
    "              'Longitude' : 'float'\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cch = ['Visit Date','Client ID','Client Age','Client Gender','City','Latitude','Longitude','Household ID','Household Size',\n",
    "'Household Primary Income Source','Program Name','HH Mem 1- ID','HH Mem 1- Age','HH Mem 1- Gender',\n",
    "'HH Mem 2- ID','HH Mem 2- Age','HH Mem 2- Gender','HH Mem 3- ID','HH Mem 3- Age','HH Mem 3- Gender',\n",
    "'HH Mem 4- ID','HH Mem 4- Age','HH Mem 4- Gender','HH Mem 5- ID','HH Mem 5- Age','HH Mem 5- Gender','HH Mem 6- ID',\n",
    "'HH Mem 6- Age','HH Mem 6- Gender','HH Mem 7- ID','HH Mem 7- Age','HH Mem 7- Gender','HH Mem 8- ID','HH Mem 8- Age',\n",
    "'HH Mem 8- Gender','HH Mem 9- ID','HH Mem 9- Age','HH Mem 9- Gender','HH Mem 10- ID','HH Mem 10- Age','HH Mem 10- Gender',\n",
    "'HH Mem 11- ID','HH Mem 11- Age','HH Mem 11- Gender','HH Mem 12- ID','HH Mem 12- Age','HH Mem 12- Gender',\n",
    "'HH Mem 13- ID','HH Mem 13- Age','HH Mem 13- Gender','HH Mem 14- ID','HH Mem 14- Age','HH Mem 14- Gender',\n",
    "'HH Mem 15- ID','HH Mem 15- Age','HH Mem 15- Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fhh =['Visit Date','Client ID','Client Age','Client Gender','City','Latitude','Longitude','Household ID',\n",
    "      'Household Size','Household Primary Income Source','HH Mem 1- ID','HH Mem 1- Age','HH Mem 1- Gender',\n",
    "'HH Mem 2- ID','HH Mem 2- Age','HH Mem 2- Gender','HH Mem 3- ID','HH Mem 3- Age','HH Mem 3- Gender',\n",
    "'HH Mem 4- ID','HH Mem 4- Age','HH Mem 4- Gender','HH Mem 5- ID','HH Mem 5- Age','HH Mem 5- Gender','HH Mem 6- ID',\n",
    "'HH Mem 6- Age','HH Mem 6- Gender','HH Mem 7- ID','HH Mem 7- Age','HH Mem 7- Gender','HH Mem 8- ID','HH Mem 8- Age',\n",
    "'HH Mem 8- Gender','HH Mem 9- ID','HH Mem 9- Age','HH Mem 9- Gender','HH Mem 10- ID','HH Mem 10- Age','HH Mem 10- Gender',\n",
    "'HH Mem 11- ID','HH Mem 11- Age','HH Mem 11- Gender','HH Mem 12- ID','HH Mem 12- Age','HH Mem 12- Gender',\n",
    "'HH Mem 13- ID','HH Mem 13- Age','HH Mem 13- Gender','HH Mem 14- ID','HH Mem 14- Age','HH Mem 14- Gender',\n",
    "'HH Mem 15- ID','HH Mem 15- Age','HH Mem 15- Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open the file of source data: visits to the programs and other information exported from l2f\n",
    "fh_path = 'source_files/EFHP_full_year_caseload_2018.csv' # EFHP caseload\n",
    "cc_path = 'source_files/cc2018.csv' # community programs\n",
    "data1 = pd.read_csv(fh_path, usecols=fhh, dtype=data_types, low_memory=False) # EFHP\n",
    "data2 = pd.read_csv(cc_path, usecols=cch, dtype=data_types, low_memory=False)\n",
    "data1['Program Name'] = 'EFHP' # program name column is missing, so add it with EFHP as the value\n",
    "data = pd.concat([data1,data2], axis =0, ignore_index=True, sort=False) # combine both datasets into one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_file = 'hof_2018_food_programs' # string to prepend to output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_neighbourhood(row):\n",
    "    '''\n",
    "    uses the Neighbourhoods class to extract the neighbourhood\n",
    "    or 'Unknown' if the lat and long are not in the csv\n",
    "    can be used in a lambda function to through .apply method to\n",
    "    create a new column with a neighbourhood value in it\n",
    "    '''\n",
    "    lat_lng = (row['Latitude'], row['Longitude'])\n",
    "    if all(lat_lng):\n",
    "        return kw.find_in_shapes(*lat_lng)\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a column that contains the neighbourhood based off the values in the Latitude and Longitude column\n",
    "data['Neighbourhood'] = data.apply(lambda row: find_neighbourhood(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write out a new version of the source csv with a neighbourhood column\n",
    "data.to_csv('~/datascience/mapping_notebooks/output_files/{}_with_neighbourhoods.csv'.format(source_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# what are the neighbourhoods that Households have visited.\n",
    "# note: False, is passed through by kw_neighbourhoods as the HH is not in KW, or no valid [lat, lng] was available\n",
    "# for them in the dataset.\n",
    "data['Neighbourhood'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(kw.nhood_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# have a look to see if things worked properly\n",
    "data['Neighbourhood'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop the records that do not contain a valid neighbourhood\n",
    "data = data[data.Neighbourhood != False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Neighbourhood'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets cleanup the source of income fields and aggregate some of the values where it makes sense\n",
    "# first, what values are there?\n",
    "data['Household Primary Income Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change nan values to 'unknown'\n",
    "data['Household Primary Income Source'].fillna('Unknown or None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# streamline the SOI field with a mapping of five categories\n",
    "prov = 'Provincial'\n",
    "fed = 'Federal'\n",
    "other = 'Other'\n",
    "no_un = 'Unknown or None'\n",
    "emp = 'Partial or full time employment'\n",
    "\n",
    "soi_map = {\n",
    "    'Ontario Works (OW)': prov, \n",
    "    'No Income': no_un,\n",
    "    'Ontario Disability Support Program (ODSP)': prov,\n",
    "    'Canadian Pension Plan (CPP)': fed, \n",
    "    'Private Disability': other, \n",
    "    'Immigration': fed,\n",
    "    'Employed: Full-Time': emp, \n",
    "    'Employed: Part-Time': emp, \n",
    "    'Child Support': other,\n",
    "    'Old Age Security (OAS)': fed, \n",
    "    'Employment Insurance (EI)': fed,\n",
    "    'Other (Specify)': other,\n",
    "    'Child Tax Benefit': fed,\n",
    "    'Self Employed': emp,\n",
    "    'Student Loans': other,\n",
    "    'Temporary Work': emp,\n",
    "    'WSIB': prov,\n",
    "    'Universal Child Benefit': fed,\n",
    "    \"Children's Aid\": other,\n",
    "    'Private Pension': other,\n",
    "    'Family Support': other,\n",
    "    'Spouse/Family Support': other,\n",
    "    'Scholarships': other,\n",
    "    'provincial_disability': prov,\n",
    "    'Unknown': no_un\n",
    "}\n",
    "\n",
    "# this will change values to what we prefer\n",
    "data['Household Primary Income Source'] = data['Household Primary Income Source'].replace(soi_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Household Primary Income Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# group the data by households and pull out the first occurance of each unique 'Household ID'\n",
    "# https://stackoverflow.com/questions/20067636/pandas-dataframe-get-first-row-of-each-group\n",
    "households = data.groupby('Household ID').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count the number of occurances of the Household ID - a way to count household visits for some service\n",
    "# (due to the way that L2F deals with household members moving between households, there is likely some double counting involved)\n",
    "# Insert the count as a new column\n",
    "households['Number of Visits'] = data['Household ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset the index and now we have a dataset with Household data aggregated a bit, with a number of visits and neighbourhood data\n",
    "households.reset_index(inplace=True)\n",
    "households.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many unique HH id's?\n",
    "households['Household ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now groupby Neighbourhood so we can start generating some Neighbourhood level stats\n",
    "# especially HH size, visits and income source\n",
    "nhood_data = households.groupby(['Neighbourhood', 'Household Primary Income Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what functions do we want to apply to each column to get some basic stats?\n",
    "agg_functions = {'Household ID': 'count', 'Household Size': ['mean', 'sum'], 'Number of Visits': ['mean', 'sum']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats_nhoods = nhood_data.agg(agg_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort the neighbourhoods by neighbourhood name, and then visit count starting with the highest\n",
    "sorted_nhoods = stats_nhoods.reset_index().sort_values(['Neighbourhood',('Household ID', 'count')], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to a csv if you want\n",
    "sorted_nhoods.to_csv('output_files/hof_2018_Caseload_Neighbourhood_Summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_nhoods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AGGREGATE BY NEIGHBOURHOOD\n",
    "nhood_aggregation = households.groupby('Neighbourhood')\n",
    "nh_s = nhood_aggregation.agg({'Household ID': 'count'})\n",
    "nh_s.reset_index(inplace=True)\n",
    "# MAKE A SERIES that maps Neighbourhood to the sum of the number of HH there\n",
    "nh_hh = pd.Series(list(nh_s['Household ID']), index= list(nh_s['Neighbourhood']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for example how mnay HH live in 'ALPINE'\n",
    "nh_hh['ALPINE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nh_hh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Data by City Neighbourhood and Source of Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookup_total(row, index_series):\n",
    "    '''\n",
    "    takes a row and places the value in the Neighbourhood column\n",
    "    i.e. ALPINE into a variable and then looks for it in the index_series\n",
    "    which is a mapping of Neighbourhood to total number of HH in that neighbourhood \n",
    "    '''\n",
    "    hood = row['Neighbourhood']\n",
    "    return index_series[hood]\n",
    "    \n",
    "def return_city(row):\n",
    "    '''\n",
    "    to avoid errors resulting from bad inputs (city mismatch vs address, mis-spellings etc) that was \n",
    "    more common before the new address field formatting, we can use the fact that \n",
    "    in the neighbourhoods dataset, Kitchener Neighbourhoods are in caps and Waterloo\n",
    "    are sentenance case.  This function will allow the insertion of a standardized City into a new\n",
    "    column.\n",
    "    \n",
    "    Otherwise there are mispellings, address city mismatches and other oddities\n",
    "    \n",
    "    '''\n",
    "    hood = row['Neighbourhood']\n",
    "    if not hood:\n",
    "        return 'Unknown'\n",
    "    elif hood.isupper():\n",
    "        return 'Kitchener'\n",
    "    else:\n",
    "        return 'Waterloo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert a new column into the data dataframe with a total HH in each Neighbourhood\n",
    "data['Neighbourhood HH Total'] = data.apply(lambda row: lookup_total(row, nh_hh), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert the City value implied by the neighbourhood from the supplied geocoordinates\n",
    "data['Implied_City'] = data.apply(lambda row: return_city(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new sortby data object that references the new column \n",
    "hh_totals = data.groupby('Household ID').first()\n",
    "hh_totals['Number of Visits'] = data['Household ID'].value_counts()\n",
    "hh_totals.reset_index(inplace=True)\n",
    "\n",
    "hh_nhood_data = hh_totals.groupby(['Neighbourhood', 'Implied_City', 'Neighbourhood HH Total', 'Household Primary Income Source'])\n",
    "hh_stats_nhoods = hh_nhood_data.agg(agg_functions)\n",
    "hh_sorted_nhoods = hh_stats_nhoods.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write a csv of the summarized data\n",
    "xname = 'output_files/hof_2018_EFHP_Caseload_HH_NH_summary.csv'\n",
    "hh_sorted_nhoods.sort_values(['Neighbourhood HH Total',('Household ID', 'count')], ascending=False).to_csv(xname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary stats by neighbourhood and SOI, visits and family size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh_sorted_nhoods.sort_values(['Neighbourhood HH Total',('Household ID', 'count')], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neighbourhood Aggregate totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html\n",
    "n_hood_totals = data.sort_values('Neighbourhood HH Total', \n",
    "                                 ascending=False).drop_duplicates(subset=['Neighbourhood', \n",
    "                                                                          'Implied_City'], \n",
    "                                                                           keep='last')\n",
    "n_hood_totals.reset_index(inplace=True)\n",
    "sorted_nhood_totals= n_hood_totals[['Neighbourhood', 'Implied_City','Neighbourhood HH Total']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_nhood_totals.to_csv('output_files/hof_2018_caseload_neighbourhood_totals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
